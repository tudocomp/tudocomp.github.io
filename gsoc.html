<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale = 1, maximum-scale=1, user-scalable=no"/>
    <!-- TODO: Meta / OpenGraph / Facebook -->
    <!-- TODO: read Pandoc's meta --><title>tudocomp</title>
    <link rel="stylesheet" type="text/css" href="font-awesome-4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" type="text/css" href="fonts/fonts.css"/>
    <link rel="stylesheet" type="text/css" href="style.css"/>
    <link rel="icon" type="image/svg+xml" href="tudocomp-icon.svg">

    <!-- Chrome currently doesn't support SVG favicons -->
    <link rel="icon" type="image/png" href="tudocomp-icon.png">
</head>
<body>
    <header>
        <h1>&ndash; The TU Dortmund Compression Framework</h1>
    </header>
    <section id="content" class="padded">
    <h1 id="project-ideas-list">Project Ideas List</h1>
    <p>We maintain an up-to-date list of medium size projects at this page. The projects are self-contained, and consist of enhancements and improvements. Our project ideas range from projects targeted at nice-to-heave features to projects related to scientific research in the field of data compression. For all these projects, participating students should be interested in data compression in general, and in at least in one of the following fields in particular: low-level programming, string data structures, algorithm engineering. We welcome everybody (not just students) to take part in the tudocomp framework by participating at one of the listed projects.</p>
    <p>Please have a look at the <a href="tudocomp%20homepage">http://tudocomp.org</a> to get a glimpse on what is this framework all about. Also, tudocomp's sourcecode is publicly available at <a href="github">https://github.com/tudocomp/tudocomp</a>.</p>
    <h2 id="general-info">General Info</h2>
    <p>For participating as a tudocomp contributor, the following steps should be made:</p>
    <ul>
    <li>One should get familiar with git</li>
    <li>Please create your own github branch</li>
    <li>Push stable achievements back to the main repository by pull requests.</li>
    </ul>
    <p>Under <em>stable</em> we understand that the code is</p>
    <ul>
    <li>compilable</li>
    <li>well commented to the extend that the code is easily understandable</li>
    <li>compliant to our coding standards</li>
    </ul>
    <p>Communication during coding is necessary:</p>
    <ul>
    <li>architecture may have to change</li>
    <li>there may be bugs or strange behavior in our project of which we either are unaware of, or has not yet been fixed</li>
    </ul>
    <p>For communication:</p>
    <ul>
    <li>use ticket system</li>
    <li>send email on a regular basis for discussion</li>
    <li>keep an up-to-date diary about the current state of your project. The dairy should show how the project evolves and progresses.</li>
    <li>give regularly to the community over the mailing list</li>
    <li>if needed, ask your mentors about further communication channels, e.g., Skype.</li>
    </ul>
    <p>We advocate anybody to fork the project, and start their own implementation of compression algorithms.</p>
    <h2 id="gsoc-timeline">GSoC Timeline</h2>
    <p>Here is the general GSoC 2017 timeline, with important <em>hard</em> deadlines for all projects: <a href="">https://developers.google.com/open-source/gsoc/timeline</a></p>
    <h2 id="project-plan">Project Plan</h2>
    <p>Project planning is necessary to structure how and when which parts of a project have to be done. The first step of starting a project is to set up a detailed project plan. The plan can be realized with tickets bundled in milestones, and a Gantt diagram. The project plan includes intermediate and secondary goals and deliveries with clear deadlines, as well as reasonable goals for midterm evaluation. Add slack times for the time ranges were you might not be available. While working on a project, the project plan should indicate where you are at the moment, i.e., what has (not yet) been done at any point of time. If the time line drifts apart from what was expected by the project planning, then get in touch with your mentors. Your diary has to be updated on a regular basis (e.g., what problems have occurred / have been resolved, what is behind of schedule).</p>
    <h2 id="gsoc-2017-ideas">GSoc 2017 Ideas</h2>
    <p>The following collection are our project ideas we propose for GSoC 2017. If you have further project ideas and or want to discuss some of our proposed project please contact us by email (tudocomp.cs@lists.tu-dortmund.de). You can also subscribe and follow the discussions on the mailing lists to see what is going on.</p>
    <h3 id="review-of-coding-strategies">Review of Coding Strategies</h3>
    <p>tudocomp currently provides only a canonical Huffman coder and a customized . Novel coding algorithms provide better precision than Huffman coder, and are faster than arithmetic coding. It is interesting to integrate general codings like ASM or FSE or specialized codings like ETDC into tudocomp, and evaluate all codings in respect to their compression ratio and compression/decompression time.</p>
    <p><em>References:</em></p>
    <ul>
    <li><a href="ETDC%20for%20natural%20language%20text%20compression">https://www.dcc.uchile.cl/~gnavarro/ps/ir06.pdf</a></li>
    <li><a href="Asymmetric%20Numeral%20Systems">https://arxiv.org/pdf/1311.2540.pdf</a></li>
    <li><a href="FSE%20Encoder">https://github.com/Cyan4973/FiniteStateEntropy</a></li>
    </ul>
    <p><em>Category</em>: Encodings</p>
    <h3 id="areacomp">AreaComp</h3>
    <p>The idea of AreaComp is to substitute all frequent and large substrings of a text. We search for the substring that maximizes the value of a cost function. The cost function weights the number of occurrences and the length of a substring, e.g., the multiplication of the length and the number of occurrences is a natural choice.</p>
    <p>Given the suffix array and the longest common prefix array, we can find the number of occurrences of a substring in the text by looking at both arrays. A naive approach would store all substrings of a certain length occurring at least twice in a priority queue, with its cost function value as its key. We take the root (i.e., the best substring w.r.t. the cost function) from the heap, substitute its occurrences and update the suffix array and longest common prefix array. There is a similar method called ``greedy off-line textual substitution'' that considers all non-overlapping occurrences.</p>
    <p><em>Category</em>: Compressor</p>
    <p>References</p>
    <ul>
    <li><a href="Off-line%20compression%20by%20greedy%20textual%20substitution">http://ieeexplore.ieee.org/iel5/5/19320/00892709.pdf</a></li>
    <li><a href="Data%20structures%20and%20algorithms%20for%20the%20string%20statistics%20problem">http://link.springer.com/article/10.1007/BF01955046</a></li>
    </ul>
    <h3 id="clever-tie-breaking-for-lcpcomp">Clever Tie Breaking for lcpcomp</h3>
    <p>Our compressor <a href="lcpcomp">https://github.com/tudocomp/tudocomp/blob/public/include/tudocomp/compressors/LCPCompressor.hpp</a> (implemented in tudocomp) is a longest-first greedy compression algorithm. Given multiple longest substrings, there is no strict tie breaking rule that states which longest substring to choose. The focus of this project is to enhance the lcpcomp compressors with a hinting which substring it should choose. The hinting can be based on the selection of a tie breaking rule with the best expectation in terms of compression ratio or decompression speed.</p>
    <p><em>References</em></p>
    <ul>
    <li>this problem is similar to a <a href="semi-greedy%20variant%20of%20LZ77">http://link.springer.com/chapter/10.1007/978-3-642-82456-2_11</a></li>
    </ul>
    <h2 id="k-maxsat-for-lcpcomp">k-maxsat for lcpcomp</h2>
    <p>Decompressing an lcpcomp compressed file is a heavy task with respect to time. That is because references of lcpcomp can be nested, i.e., a reference refers to a substring that got replaced with another reference. The nesting of references can form long dependency chains that need to be resolved before the actual decompression can take place. This project focuses on a modification of the compression phase, where we want to check whether it is possible to cirumvent the production of long dependency lines. It can be shown that this problem relates to the k-maxsat problem. An approximation algorithm for the k-maxsat problem shall be devised in this project.</p>
    <p><em>References</em></p>
    <ul>
    <li>Mayr, Ernst W., Prömel, Hans Jürgen, Steger, Angelika: &quot;Lectures on Proof Verification and Approximation Algorithms&quot;, the MaxEkSat-Problem</li>
    </ul>
    <h3 id="efficient-integer-coders">Efficient Integer Coders</h3>
    <p>Implement and evaluate a fast Fibonacci encoding Algorithm. Fibonacci coding is a universal code that represents integers succinctly. The coding splits an integer up to summands that are Fibonacci words. Although the coding achieves a very compact representation, it take a lot of time for decompression. Aim of this project is to implement a new encoding algorithm and measure its speed with currently avaiable Fibonacci coders.</p>
    <p><em>Category</em>: Encodings</p>
    <p><em>References</em></p>
    <ul>
    <li><a href="Fast%20Fibonacci%20Encoding%20Algorithm">http://ceur-ws.org/Vol-567/paper14.pdf</a></li>
    <li><a href="Fibonacci%20Coder%20of%20the%20SDSL">https://github.com/simongog/sdsl-lite/tree/master/include/sdsl/coder_fibonacci.hpp</a></li>
    </ul>
    <h3 id="compressed-index-with-repair">Compressed Index with Repair</h3>
    <p>Sakamoto is working on an online index data structure. Online means that characters can be appended. He uses ESP as grammar. The grammar tree is stored in post-order to allow new elements on the right side. Since the tree is a full binary tree, it can be stored in n bits if it contains n nodes (see technical report of Sadakane). The DCC paper 2016 from Kida introduces an online Re-Pair-based grammar compressor. It should be feasible to exchange ESP with the online Re-Pair-variant.</p>
    <p><em>Category</em>: Compressor</p>
    <h3 id="lz78-with-a-compact-hash-table">LZ78 with a Compact Hash Table</h3>
    <p>Our <a href="LZ78%20compressor">https://github.com/tudocomp/tudocomp/blob/public/include/tudocomp/compressors/LZ78Compressor.hpp</a> can utilize different Lempel-Ziv-78 tries like a binary trie, a ternary trie, or a trie based on a hash table. The latter is the faster, but yet heaviest trie implementation. In the light of compact hash tables, we wonder whether we can drop the memory footprint of hash table implementations while still being very fast.</p>
    <ul>
    <li><a href="Don&#39;t%20Thrash:%20How%20to%20Cache%20Your%20Hash%20on%20Flash">https://arxiv.org/abs/1208.0290</a></li>
    </ul>
    <p><em>Category</em>: Compressor, Hashing</p>
    <h3 id="serialization-of-indices">Serialization of Indices</h3>
    <p>A majority of compression algorithms use data structures that need a lot of time to process. Add a facility to build them in a preliminary step, such that they can be loaded when the actual compression has to be done. Some data structures are only needed for a linear scan such that they can be streamed from disk.</p>
    <p><em>Category</em>: External Memory Algorithms</p>
    <h3 id="string-analyzing-tools-in-javascript">String Analyzing tools in Javascript</h3>
    <p>Working with lossless compression algorithms on texts, we often experience the lack of tools that visualize text index data structures. There are some tools that provide limited insigt to some data structures. Yet, there is no a powerful and easy-to-use tool that can covers a majority of the most frequently used data structures. Aim of this project is to produce a JavaScript written web platform that interactively visualizes the most commonly used data structures like suffix arrays, longest common prefix array, etc. in text compression.</p>
    <p>References - <a href="Shinohara&#39;s%20Online%20Encyclopedia%20of%20Strings">http://www.shino.ecei.tohoku.ac.jp/stringology/</a> - <a href="Strinalze%20-%20Analyze%20a%20string%20or%20a%20sequence%20of%20generated%20strings">https://github.com/koeppl/strinalyze</a></p>
    <p><em>Category</em>: Visualization</p>
    <h3 id="integration-into-7zip">Integration into 7zip</h3>
    <p>To improve the usability of the tudocomp framework, we want the tudocomp output format to become compatible with 7z. The 7z format supports various compression techniques due to a detailed header describing the exact used compression technique. This project's aim is to adapt the 7z format for the tudocomp command line tool.</p>
    <p><em>Category</em>: Usability</p>
    <p><em>References</em></p>
    <ul>
    <li><a href="7zip">http://www.7-zip.org</a></li>
    </ul>
    <h3 id="gui-with-multiple-file---file-archiver-support">GUI with multiple file (-&gt; file archiver) support</h3>
    <p>The tudocomp framework provides only a command line tool as an interface to the end user. A end-user friendly GUI application can be beneficient for addressing command line antipathetic users. The GUI should provide the selection of multiple files/directories and an easy way to assemble a custom compression pipeline. The GUI can be programmed, for instance, in Qt oder gtkmm.</p>
    <p><em>Category</em>: GUI</p>
    <!---
    ### Try to detect text type, and use appropriate compressor.
    Modify existing 
    Neutronal Network Detetects 
    *Category* Machine Learning
    
    Target field of application: Machine Learning
    ### Survey implementation of different LCP/SA construction algorithms
    
    *Category* Algorithm Engineering
    --->
    </section>
    <footer>
    </footer>
</body>
</html>
